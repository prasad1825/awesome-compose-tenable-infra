apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2023-11-20T22:23:36Z"
    generateName: alertmanager-kube-prometheus-stack-alertmanager-
    labels:
      alertmanager: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: kube-prometheus-stack-alertmanager
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: 0.26.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-kube-prometheus-stack-alertmanager-7b7885f4cb
      statefulset.kubernetes.io/pod-name: alertmanager-kube-prometheus-stack-alertmanager-0
    name: alertmanager-kube-prometheus-stack-alertmanager-0
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-kube-prometheus-stack-alertmanager
      uid: 77bf3fe4-e2fd-4ade-a0e4-9c8c06d4f01b
    resourceVersion: "67092"
    uid: e8058e81-c310-4221-86b2-c16304ae0319
  spec:
    containers:
    - args:
      - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=
      - --web.listen-address=:9093
      - --web.external-url=http://kube-prometheus-stack-alertmanager.kube-prometheus-stack:9093
      - --web.route-prefix=/
      - --cluster.label=kube-prometheus-stack/kube-prometheus-stack-alertmanager
      - --cluster.peer=alertmanager-kube-prometheus-stack-alertmanager-0.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/prometheus/alertmanager:v0.26.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: http-web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-kube-prometheus-stack-alertmanager-db
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w9nx7
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9093/-/reload
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w9nx7
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-kube-prometheus-stack-alertmanager-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w9nx7
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-alertmanager
    serviceAccountName: kube-prometheus-stack-alertmanager
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-prometheus-stack-alertmanager-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-kube-prometheus-stack-alertmanager-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - name: web-config
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-prometheus-stack-alertmanager-web-config
    - emptyDir: {}
      name: alertmanager-kube-prometheus-stack-alertmanager-db
    - name: kube-api-access-w9nx7
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:50Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://3eb080940238ebe8d23a39f9f7013fb1fa4ec50f12ede55991ed7fb32bdb8389
      image: quay.io/prometheus/alertmanager:v0.26.0
      imageID: docker-pullable://quay.io/prometheus/alertmanager@sha256:361db356b33041437517f1cd298462055580585f26555c317df1a3caf2868552
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:24:15Z"
    - containerID: docker://ec6f75d059ee7365b3584a6349701e8f6509cacf387f178f483427d5187a8925
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:7bbe804260f37cddce47eb90809e799434e6aaed03116ce8e041b73733a022b1
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:24:15Z"
    hostIP: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://825053f3466d17b3048ba3c02f5f96f7c89add2ae5e568ff13879beb9d5d50ba
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:7bbe804260f37cddce47eb90809e799434e6aaed03116ce8e041b73733a022b1
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://825053f3466d17b3048ba3c02f5f96f7c89add2ae5e568ff13879beb9d5d50ba
          exitCode: 0
          finishedAt: "2023-11-20T22:23:49Z"
          reason: Completed
          startedAt: "2023-11-20T22:23:49Z"
    phase: Running
    podIP: 10.244.0.101
    podIPs:
    - ip: 10.244.0.101
    qosClass: Burstable
    startTime: "2023-11-20T22:23:36Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 139c5a018290d9fd3ca7cf81c819044cf2bbf22845f16a250d5f36e533fea2d0
      checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      checksum/sc-dashboard-provider-config: 7c16e5ac0ef8925a3aa9219afd7cb2acbc57394e596109c9891c23ad42cb6580
      checksum/secret: 2a107bb512b0a2f7e9db9307c8c3ad9139d3c5044f3e12669ab985e2ea80ca5b
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2023-11-20T22:23:23Z"
    generateName: kube-prometheus-stack-grafana-79f9bbc8fd-
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: grafana
      pod-template-hash: 79f9bbc8fd
    name: kube-prometheus-stack-grafana-79f9bbc8fd-kmqn5
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-grafana-79f9bbc8fd
      uid: 30f5782d-ed03-4e23-8c48-02e3b2511180
    resourceVersion: "67100"
    uid: 7b56fe08-fcd1-4788-b089-c2d67e7f5c7f
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_dashboard
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /tmp/dashboards
      - name: RESOURCE
        value: both
      - name: NAMESPACE
        value: ALL
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/dashboards/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.25.2
      imagePullPolicy: IfNotPresent
      name: grafana-sc-dashboard
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-st28p
        readOnly: true
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_datasource
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /etc/grafana/provisioning/datasources
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/datasources/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.25.2
      imagePullPolicy: IfNotPresent
      name: grafana-sc-datasources
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-st28p
        readOnly: true
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: kube-prometheus-stack-grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: kube-prometheus-stack-grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:10.1.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
        name: sc-dashboard-provider
        subPath: provider.yaml
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-st28p
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: kube-prometheus-stack-grafana
    serviceAccountName: kube-prometheus-stack-grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-prometheus-stack-grafana
      name: config
    - emptyDir: {}
      name: storage
    - emptyDir: {}
      name: sc-dashboard-volume
    - configMap:
        defaultMode: 420
        name: kube-prometheus-stack-grafana-config-dashboards
      name: sc-dashboard-provider
    - emptyDir: {}
      name: sc-datasources-volume
    - name: kube-api-access-st28p
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://26d7494ecdfc8c4b5749733c1395cd408546d42754351b9ed31aaf06c23ed3ca
      image: grafana/grafana:10.1.5
      imageID: docker-pullable://grafana/grafana@sha256:0679e877ba204cede473782d5aba962831a3449092da120aba7d24082efe3fde
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:24:07Z"
    - containerID: docker://d3f8698fbf3482dd21b8acbfb03166a6ab8c23451084a35ee9ed5ddab1ffd1ab
      image: quay.io/kiwigrid/k8s-sidecar:1.25.2
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:cb4c638ffb1fa1eb49678e0f0423564b39254533f63f4ca6a6c24260472e0c4f
      lastState: {}
      name: grafana-sc-dashboard
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:23:44Z"
    - containerID: docker://ea2061fc7714b459c01f859b86b92f0f49d7c1bef6f899f733556d8b78ee6509
      image: quay.io/kiwigrid/k8s-sidecar:1.25.2
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:cb4c638ffb1fa1eb49678e0f0423564b39254533f63f4ca6a6c24260472e0c4f
      lastState: {}
      name: grafana-sc-datasources
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:23:44Z"
    hostIP: 192.168.49.2
    phase: Running
    podIP: 10.244.0.99
    podIPs:
    - ip: 10.244.0.99
    qosClass: BestEffort
    startTime: "2023-11-20T22:23:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-11-20T22:23:23Z"
    generateName: kube-prometheus-stack-kube-state-metrics-7ccc7bb9c9-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.10.1
      helm.sh/chart: kube-state-metrics-5.15.2
      pod-template-hash: 7ccc7bb9c9
      release: kube-prometheus-stack
    name: kube-prometheus-stack-kube-state-metrics-7ccc7bb9c9-dzq4g
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-kube-state-metrics-7ccc7bb9c9
      uid: 0fed1aea-d29a-4954-bb30-afcc8d2a5c1d
    resourceVersion: "67013"
    uid: 0ae20b15-5a4c-45d8-a693-0891d22f273e
  spec:
    containers:
    - args:
      - --port=8080
      - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dsjlx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-kube-state-metrics
    serviceAccountName: kube-prometheus-stack-kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dsjlx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:44Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:44Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://7e3fc7bef5191a260137b46fe379a6b8d6f7d92da4bca227327dfe7678706cf1
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
      imageID: docker-pullable://registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:af8220f534938de121a694cb7314313a6195c9d494fc30bfa6885b08a276bb82
      lastState: {}
      name: kube-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:23:31Z"
    hostIP: 192.168.49.2
    phase: Running
    podIP: 10.244.0.98
    podIPs:
    - ip: 10.244.0.98
    qosClass: BestEffort
    startTime: "2023-11-20T22:23:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-11-20T22:23:23Z"
    generateName: kube-prometheus-stack-operator-5cffdd6b96-
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      pod-template-hash: 5cffdd6b96
      release: kube-prometheus-stack
    name: kube-prometheus-stack-operator-5cffdd6b96-87jhq
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-prometheus-stack-operator-5cffdd6b96
      uid: 25b36a3f-679e-402f-a3cc-e7f3aa03c98b
    resourceVersion: "66980"
    uid: 70e4e79d-9b99-4812-9bb0-960e9e9b84f0
  spec:
    containers:
    - args:
      - --kubelet-service=kube-system/kube-prometheus-stack-kubelet
      - --localhost=127.0.0.1
      - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      - --config-reloader-cpu-request=0
      - --config-reloader-cpu-limit=0
      - --config-reloader-memory-request=0
      - --config-reloader-memory-limit=0
      - --thanos-default-base-image=quay.io/thanos/thanos:v0.32.5
      - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
      - --web.enable-tls=true
      - --web.cert-file=/cert/cert
      - --web.key-file=/cert/key
      - --web.listen-address=:10250
      - --web.tls-min-version=VersionTLS13
      image: quay.io/prometheus-operator/prometheus-operator:v0.69.1
      imagePullPolicy: IfNotPresent
      name: kube-prometheus-stack
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cert
        name: tls-secret
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qsb5v
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-operator
    serviceAccountName: kube-prometheus-stack-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: tls-secret
      secret:
        defaultMode: 420
        secretName: kube-prometheus-stack-admission
    - name: kube-api-access-qsb5v
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ea2049ca7545bae4a3a32d377b99e1b874a2f796b3ad9007350b79fa9ce0f1f0
      image: quay.io/prometheus-operator/prometheus-operator:v0.69.1
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-operator@sha256:ecc59d98c331f8831358425fd29e2343a95e24fdb264ed83cccaca552d9c97d9
      lastState: {}
      name: kube-prometheus-stack
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:23:36Z"
    hostIP: 192.168.49.2
    phase: Running
    podIP: 10.244.0.97
    podIPs:
    - ip: 10.244.0.97
    qosClass: BestEffort
    startTime: "2023-11-20T22:23:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2023-11-20T22:23:23Z"
    generateName: kube-prometheus-stack-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.6.1
      controller-revision-hash: 75454946c
      helm.sh/chart: prometheus-node-exporter-4.23.2
      jobLabel: node-exporter
      pod-template-generation: "1"
      release: kube-prometheus-stack
    name: kube-prometheus-stack-prometheus-node-exporter-5hd5f
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-prometheus-stack-prometheus-node-exporter
      uid: dae3fcb8-855f-4388-8376-cf94bf9c29c4
    resourceVersion: "66922"
    uid: b4be00d0-8578-46fb-b4f2-7bad2526b416
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.6.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: kube-prometheus-stack-prometheus-node-exporter
    serviceAccountName: kube-prometheus-stack-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://bc0df9c74bb7278c60b1b5602576027e84d108e95d2e0746cd72cd4d1395323b
      image: quay.io/prometheus/node-exporter:v1.6.1
      imageID: docker-pullable://quay.io/prometheus/node-exporter@sha256:81f94e50ea37a88dfee849d0f4acad25b96b397061f59e5095905f6bc5829637
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:23:29Z"
    hostIP: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2023-11-20T22:23:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2023-11-20T22:23:37Z"
    generateName: prometheus-kube-prometheus-stack-prometheus-
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack-prometheus
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/version: 2.47.2
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-kube-prometheus-stack-prometheus-57b4489d55
      operator.prometheus.io/name: kube-prometheus-stack-prometheus
      operator.prometheus.io/shard: "0"
      prometheus: kube-prometheus-stack-prometheus
      statefulset.kubernetes.io/pod-name: prometheus-kube-prometheus-stack-prometheus-0
    name: prometheus-kube-prometheus-stack-prometheus-0
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-kube-prometheus-stack-prometheus
      uid: 2dc54ab3-a898-40bf-8f84-8a9cf4e160e0
    resourceVersion: "67127"
    uid: 1d8d7a47-9498-4272-8678-05c864327f16
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --web.enable-lifecycle
      - --web.external-url=http://kube-prometheus-stack-prometheus.kube-prometheus-stack:9090
      - --web.route-prefix=/
      - --storage.tsdb.retention.time=10d
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.wal-compression
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/prometheus/prometheus:v2.47.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: http-web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-kube-prometheus-stack-prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lxxnz
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lxxnz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-kube-prometheus-stack-prometheus-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lxxnz
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: kube-prometheus-stack-prometheus
    serviceAccountName: kube-prometheus-stack-prometheus
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-stack-prometheus
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-kube-prometheus-stack-prometheus-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
      name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-stack-prometheus-web-config
    - emptyDir: {}
      name: prometheus-kube-prometheus-stack-prometheus-db
    - name: kube-api-access-lxxnz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:24:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-11-20T22:23:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ae7b7bbaa0303f7d81a36f70f03f45b3cec17016ddfa5854b78b13e9d3f2b77d
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:7bbe804260f37cddce47eb90809e799434e6aaed03116ce8e041b73733a022b1
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:24:27Z"
    - containerID: docker://c0b398cd7920e822ef6061cf19f0a5566a68245f4507bab6a99431562e4b7ed7
      image: quay.io/prometheus/prometheus:v2.47.2
      imageID: docker-pullable://quay.io/prometheus/prometheus@sha256:3002935850ea69a59816825d4cb718fafcdb9b124e4e6153ebc6894627525f7f
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-11-20T22:24:26Z"
    hostIP: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://17bceb1145704ab0a66ddc608a309649dcd42fe4183fccbaf12b67901d7651df
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:7bbe804260f37cddce47eb90809e799434e6aaed03116ce8e041b73733a022b1
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://17bceb1145704ab0a66ddc608a309649dcd42fe4183fccbaf12b67901d7651df
          exitCode: 0
          finishedAt: "2023-11-20T22:23:51Z"
          reason: Completed
          startedAt: "2023-11-20T22:23:51Z"
    phase: Running
    podIP: 10.244.0.102
    podIPs:
    - ip: 10.244.0.102
    qosClass: BestEffort
    startTime: "2023-11-20T22:23:37Z"
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2023-11-20T22:23:36Z"
    labels:
      operated-alertmanager: "true"
    name: alertmanager-operated
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Alertmanager
      name: kube-prometheus-stack-alertmanager
      uid: fd4584b2-992c-4d09-952b-bc26fae6ed50
    resourceVersion: "66961"
    uid: 55662af5-bab1-4d97-ab5e-90ac102b23b2
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: http-web
    - name: tcp-mesh
      port: 9094
      protocol: TCP
      targetPort: 9094
    - name: udp-mesh
      port: 9094
      protocol: UDP
      targetPort: 9094
    selector:
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      release: kube-prometheus-stack
      self-monitor: "true"
    name: kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    resourceVersion: "66781"
    uid: eed96ef5-5273-4fc5-9111-48ae670557ed
  spec:
    clusterIP: 10.110.155.232
    clusterIPs:
    - 10.110.155.232
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9093
      protocol: TCP
      targetPort: 9093
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      alertmanager: kube-prometheus-stack-alertmanager
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 10.1.5
      helm.sh/chart: grafana-7.0.6
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    resourceVersion: "66779"
    uid: 8d6cc63c-1646-41aa-8f63-5faae46b36cd
  spec:
    clusterIP: 10.99.75.44
    clusterIPs:
    - 10.99.75.44
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 80
      protocol: TCP
      targetPort: 3000
    selector:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: grafana
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
      prometheus.io/scrape: "true"
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.10.1
      helm.sh/chart: kube-state-metrics-5.15.2
      release: kube-prometheus-stack
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    resourceVersion: "66756"
    uid: 57758144-18d5-482f-a8b1-974673141e2f
  spec:
    clusterIP: 10.98.187.254
    clusterIPs:
    - 10.98.187.254
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: kube-state-metrics
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      release: kube-prometheus-stack
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    resourceVersion: "66787"
    uid: 90465140-4aa2-47ed-b83a-3397e297c52a
  spec:
    clusterIP: 10.106.129.75
    clusterIPs:
    - 10.106.129.75
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app: kube-prometheus-stack-operator
      release: kube-prometheus-stack
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      release: kube-prometheus-stack
      self-monitor: "true"
    name: kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    resourceVersion: "66774"
    uid: 1a24bf4c-28fc-4671-94ec-f490ea88bca6
  spec:
    clusterIP: 10.109.143.78
    clusterIPs:
    - 10.109.143.78
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: 9090
    - appProtocol: http
      name: reloader-web
      port: 8080
      protocol: TCP
      targetPort: reloader-web
    selector:
      app.kubernetes.io/name: prometheus
      operator.prometheus.io/name: kube-prometheus-stack-prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
      prometheus.io/scrape: "true"
    creationTimestamp: "2023-11-20T22:23:23Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.6.1
      helm.sh/chart: prometheus-node-exporter-4.23.2
      jobLabel: node-exporter
      release: kube-prometheus-stack
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    resourceVersion: "66765"
    uid: 607539ac-cee4-4608-88cf-f32529e0fdcd
  spec:
    clusterIP: 10.97.206.154
    clusterIPs:
    - 10.97.206.154
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: prometheus-node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2023-11-20T22:23:37Z"
    labels:
      operated-prometheus: "true"
    name: prometheus-operated
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      kind: Prometheus
      name: kube-prometheus-stack-prometheus
      uid: 491ef652-1abf-4b14-8cd7-4b1573fb6483
    resourceVersion: "66988"
    uid: d8b74fcc-b559-46ab-aebc-b371fed54c4d
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-web
      port: 9090
      protocol: TCP
      targetPort: http-web
    selector:
      app.kubernetes.io/name: prometheus
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.6.1
      helm.sh/chart: prometheus-node-exporter-4.23.2
      jobLabel: node-exporter
      release: kube-prometheus-stack
    name: kube-prometheus-stack-prometheus-node-exporter
    namespace: kube-prometheus-stack
    resourceVersion: "66925"
    uid: dae3fcb8-855f-4388-8376-cf94bf9c29c4
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/name: prometheus-node-exporter
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-node-exporter
          app.kubernetes.io/part-of: prometheus-node-exporter
          app.kubernetes.io/version: 1.6.1
          helm.sh/chart: prometheus-node-exporter-4.23.2
          jobLabel: node-exporter
          release: kube-prometheus-stack
      spec:
        automountServiceAccountToken: false
        containers:
        - args:
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --path.rootfs=/host/root
          - --path.udev.data=/host/root/run/udev/data
          - --web.listen-address=[$(HOST_IP)]:9100
          - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
          - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
          env:
          - name: HOST_IP
            value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.6.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
          - containerPort: 9100
            name: http-metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
            readOnly: true
          - mountPath: /host/sys
            name: sys
            readOnly: true
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: kube-prometheus-stack-prometheus-node-exporter
        serviceAccountName: kube-prometheus-stack-prometheus-node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 10.1.5
      helm.sh/chart: grafana-7.0.6
    name: kube-prometheus-stack-grafana
    namespace: kube-prometheus-stack
    resourceVersion: "67104"
    uid: 93a5717e-59cf-4eda-b55b-2796ccff7134
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 139c5a018290d9fd3ca7cf81c819044cf2bbf22845f16a250d5f36e533fea2d0
          checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
          checksum/sc-dashboard-provider-config: 7c16e5ac0ef8925a3aa9219afd7cb2acbc57394e596109c9891c23ad42cb6580
          checksum/secret: 2a107bb512b0a2f7e9db9307c8c3ad9139d3c5044f3e12669ab985e2ea80ca5b
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/name: grafana
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.25.2
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.25.2
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:10.1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: kube-prometheus-stack-grafana
        serviceAccountName: kube-prometheus-stack-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-prometheus-stack-grafana
          name: config
        - emptyDir: {}
          name: storage
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: kube-prometheus-stack-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2023-11-20T22:24:24Z"
      lastUpdateTime: "2023-11-20T22:24:24Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2023-11-20T22:23:23Z"
      lastUpdateTime: "2023-11-20T22:24:24Z"
      message: ReplicaSet "kube-prometheus-stack-grafana-79f9bbc8fd" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.10.1
      helm.sh/chart: kube-state-metrics-5.15.2
      release: kube-prometheus-stack
    name: kube-prometheus-stack-kube-state-metrics
    namespace: kube-prometheus-stack
    resourceVersion: "67017"
    uid: 490e8344-7dcf-4c42-91cf-505f077b4d3f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/name: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.10.1
          helm.sh/chart: kube-state-metrics-5.15.2
          release: kube-prometheus-stack
      spec:
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-kube-state-metrics
        serviceAccountName: kube-prometheus-stack-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2023-11-20T22:23:44Z"
      lastUpdateTime: "2023-11-20T22:23:44Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2023-11-20T22:23:23Z"
      lastUpdateTime: "2023-11-20T22:23:44Z"
      message: ReplicaSet "kube-prometheus-stack-kube-state-metrics-7ccc7bb9c9" has
        successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      release: kube-prometheus-stack
    name: kube-prometheus-stack-operator
    namespace: kube-prometheus-stack
    resourceVersion: "66986"
    uid: 06f6dde4-568c-403c-878c-375a21481677
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        release: kube-prometheus-stack
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 54.1.0
          chart: kube-prometheus-stack-54.1.0
          heritage: Helm
          release: kube-prometheus-stack
      spec:
        containers:
        - args:
          - --kubelet-service=kube-system/kube-prometheus-stack-kubelet
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.32.5
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          image: quay.io/prometheus-operator/prometheus-operator:v0.69.1
          imagePullPolicy: IfNotPresent
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-operator
        serviceAccountName: kube-prometheus-stack-operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: kube-prometheus-stack-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2023-11-20T22:23:37Z"
      lastUpdateTime: "2023-11-20T22:23:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2023-11-20T22:23:23Z"
      lastUpdateTime: "2023-11-20T22:23:37Z"
      message: ReplicaSet "kube-prometheus-stack-operator-5cffdd6b96" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/name: grafana
      pod-template-hash: 79f9bbc8fd
    name: kube-prometheus-stack-grafana-79f9bbc8fd
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-prometheus-stack-grafana
      uid: 93a5717e-59cf-4eda-b55b-2796ccff7134
    resourceVersion: "67103"
    uid: 30f5782d-ed03-4e23-8c48-02e3b2511180
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/name: grafana
        pod-template-hash: 79f9bbc8fd
    template:
      metadata:
        annotations:
          checksum/config: 139c5a018290d9fd3ca7cf81c819044cf2bbf22845f16a250d5f36e533fea2d0
          checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
          checksum/sc-dashboard-provider-config: 7c16e5ac0ef8925a3aa9219afd7cb2acbc57394e596109c9891c23ad42cb6580
          checksum/secret: 2a107bb512b0a2f7e9db9307c8c3ad9139d3c5044f3e12669ab985e2ea80ca5b
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/name: grafana
          pod-template-hash: 79f9bbc8fd
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: NAMESPACE
            value: ALL
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.25.2
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: LABEL_VALUE
            value: "1"
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.25.2
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: kube-prometheus-stack-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: kube-prometheus-stack-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:10.1.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: kube-prometheus-stack-grafana
        serviceAccountName: kube-prometheus-stack-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-prometheus-stack-grafana
          name: config
        - emptyDir: {}
          name: storage
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: kube-prometheus-stack-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.10.1
      helm.sh/chart: kube-state-metrics-5.15.2
      pod-template-hash: 7ccc7bb9c9
      release: kube-prometheus-stack
    name: kube-prometheus-stack-kube-state-metrics-7ccc7bb9c9
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-prometheus-stack-kube-state-metrics
      uid: 490e8344-7dcf-4c42-91cf-505f077b4d3f
    resourceVersion: "67016"
    uid: 0fed1aea-d29a-4954-bb30-afcc8d2a5c1d
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/name: kube-state-metrics
        pod-template-hash: 7ccc7bb9c9
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.10.1
          helm.sh/chart: kube-state-metrics-5.15.2
          pod-template-hash: 7ccc7bb9c9
          release: kube-prometheus-stack
      spec:
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-kube-state-metrics
        serviceAccountName: kube-prometheus-stack-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
    creationTimestamp: "2023-11-20T22:23:23Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      pod-template-hash: 5cffdd6b96
      release: kube-prometheus-stack
    name: kube-prometheus-stack-operator-5cffdd6b96
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kube-prometheus-stack-operator
      uid: 06f6dde4-568c-403c-878c-375a21481677
    resourceVersion: "66983"
    uid: 25b36a3f-679e-402f-a3cc-e7f3aa03c98b
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: kube-prometheus-stack-operator
        pod-template-hash: 5cffdd6b96
        release: kube-prometheus-stack
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kube-prometheus-stack-operator
          app.kubernetes.io/instance: kube-prometheus-stack
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/part-of: kube-prometheus-stack
          app.kubernetes.io/version: 54.1.0
          chart: kube-prometheus-stack-54.1.0
          heritage: Helm
          pod-template-hash: 5cffdd6b96
          release: kube-prometheus-stack
      spec:
        containers:
        - args:
          - --kubelet-service=kube-system/kube-prometheus-stack-kubelet
          - --localhost=127.0.0.1
          - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          - --config-reloader-cpu-request=0
          - --config-reloader-cpu-limit=0
          - --config-reloader-memory-request=0
          - --config-reloader-memory-limit=0
          - --thanos-default-base-image=quay.io/thanos/thanos:v0.32.5
          - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
          - --web.enable-tls=true
          - --web.cert-file=/cert/cert
          - --web.key-file=/cert/key
          - --web.listen-address=:10250
          - --web.tls-min-version=VersionTLS13
          image: quay.io/prometheus-operator/prometheus-operator:v0.69.1
          imagePullPolicy: IfNotPresent
          name: kube-prometheus-stack
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /cert
            name: tls-secret
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-operator
        serviceAccountName: kube-prometheus-stack-operator
        terminationGracePeriodSeconds: 30
        volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: kube-prometheus-stack-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
      prometheus-operator-input-hash: "1438790647210596644"
    creationTimestamp: "2023-11-20T22:23:36Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-alertmanager
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      release: kube-prometheus-stack
    name: alertmanager-kube-prometheus-stack-alertmanager
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Alertmanager
      name: kube-prometheus-stack-alertmanager
      uid: fd4584b2-992c-4d09-952b-bc26fae6ed50
    resourceVersion: "67097"
    uid: 77bf3fe4-e2fd-4ade-a0e4-9c8c06d4f01b
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        alertmanager: kube-prometheus-stack-alertmanager
        app.kubernetes.io/instance: kube-prometheus-stack-alertmanager
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: alertmanager
    serviceName: alertmanager-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: alertmanager
        creationTimestamp: null
        labels:
          alertmanager: kube-prometheus-stack-alertmanager
          app.kubernetes.io/instance: kube-prometheus-stack-alertmanager
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: alertmanager
          app.kubernetes.io/version: 0.26.0
      spec:
        containers:
        - args:
          - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --storage.path=/alertmanager
          - --data.retention=120h
          - --cluster.listen-address=
          - --web.listen-address=:9093
          - --web.external-url=http://kube-prometheus-stack-alertmanager.kube-prometheus-stack:9093
          - --web.route-prefix=/
          - --cluster.label=kube-prometheus-stack/kube-prometheus-stack-alertmanager
          - --cluster.peer=alertmanager-kube-prometheus-stack-alertmanager-0.alertmanager-operated:9094
          - --cluster.reconnect-timeout=5m
          - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: quay.io/prometheus/alertmanager:v0.26.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          name: alertmanager
          ports:
          - containerPort: 9093
            name: http-web
            protocol: TCP
          - containerPort: 9094
            name: mesh-tcp
            protocol: TCP
          - containerPort: 9094
            name: mesh-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            requests:
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
          - mountPath: /etc/alertmanager/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/alertmanager/certs
            name: tls-assets
            readOnly: true
          - mountPath: /alertmanager
            name: alertmanager-kube-prometheus-stack-alertmanager-db
          - mountPath: /etc/alertmanager/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        - args:
          - --listen-address=:8080
          - --reload-url=http://127.0.0.1:9093/-/reload
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8080
          - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
          - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
          - --watched-dir=/etc/alertmanager/config
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/alertmanager/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/alertmanager/config_out
            name: config-out
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-alertmanager
        serviceAccountName: kube-prometheus-stack-alertmanager
        terminationGracePeriodSeconds: 120
        volumes:
        - name: config-volume
          secret:
            defaultMode: 420
            secretName: alertmanager-kube-prometheus-stack-alertmanager-generated
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: alertmanager-kube-prometheus-stack-alertmanager-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - name: web-config
          secret:
            defaultMode: 420
            secretName: alertmanager-kube-prometheus-stack-alertmanager-web-config
        - emptyDir: {}
          name: alertmanager-kube-prometheus-stack-alertmanager-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: alertmanager-kube-prometheus-stack-alertmanager-7b7885f4cb
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: alertmanager-kube-prometheus-stack-alertmanager-7b7885f4cb
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: kube-prometheus-stack
      meta.helm.sh/release-namespace: kube-prometheus-stack
      prometheus-operator-input-hash: "13415881566936937814"
    creationTimestamp: "2023-11-20T22:23:37Z"
    generation: 1
    labels:
      app: kube-prometheus-stack-prometheus
      app.kubernetes.io/instance: kube-prometheus-stack
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 54.1.0
      chart: kube-prometheus-stack-54.1.0
      heritage: Helm
      operator.prometheus.io/mode: server
      operator.prometheus.io/name: kube-prometheus-stack-prometheus
      operator.prometheus.io/shard: "0"
      release: kube-prometheus-stack
    name: prometheus-kube-prometheus-stack-prometheus
    namespace: kube-prometheus-stack
    ownerReferences:
    - apiVersion: monitoring.coreos.com/v1
      blockOwnerDeletion: true
      controller: true
      kind: Prometheus
      name: kube-prometheus-stack-prometheus
      uid: 491ef652-1abf-4b14-8cd7-4b1573fb6483
    resourceVersion: "67132"
    uid: 2dc54ab3-a898-40bf-8f84-8a9cf4e160e0
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: kube-prometheus-stack-prometheus
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: prometheus
        operator.prometheus.io/name: kube-prometheus-stack-prometheus
        operator.prometheus.io/shard: "0"
        prometheus: kube-prometheus-stack-prometheus
    serviceName: prometheus-operated
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/default-container: prometheus
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: kube-prometheus-stack-prometheus
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: prometheus
          app.kubernetes.io/version: 2.47.2
          operator.prometheus.io/name: kube-prometheus-stack-prometheus
          operator.prometheus.io/shard: "0"
          prometheus: kube-prometheus-stack-prometheus
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --web.console.templates=/etc/prometheus/consoles
          - --web.console.libraries=/etc/prometheus/console_libraries
          - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
          - --web.enable-lifecycle
          - --web.external-url=http://kube-prometheus-stack-prometheus.kube-prometheus-stack:9090
          - --web.route-prefix=/
          - --storage.tsdb.retention.time=10d
          - --storage.tsdb.path=/prometheus
          - --storage.tsdb.wal-compression
          - --web.config.file=/etc/prometheus/web_config/web-config.yaml
          image: quay.io/prometheus/prometheus:v2.47.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          name: prometheus
          ports:
          - containerPort: 9090
            name: http-web
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 3
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config_out
            name: config-out
            readOnly: true
          - mountPath: /etc/prometheus/certs
            name: tls-assets
            readOnly: true
          - mountPath: /prometheus
            name: prometheus-kube-prometheus-stack-prometheus-db
          - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
            name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
          - mountPath: /etc/prometheus/web_config/web-config.yaml
            name: web-config
            readOnly: true
            subPath: web-config.yaml
        - args:
          - --listen-address=:8080
          - --reload-url=http://127.0.0.1:9090/-/reload
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
            name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - --watch-interval=0
          - --listen-address=:8080
          - --config-file=/etc/prometheus/config/prometheus.yaml.gz
          - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
          - --watched-dir=/etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
          command:
          - /bin/prometheus-config-reloader
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: SHARD
            value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.69.1
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
          - containerPort: 8080
            name: reloader-web
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/prometheus/config
            name: config
          - mountPath: /etc/prometheus/config_out
            name: config-out
          - mountPath: /etc/prometheus/rules/prometheus-kube-prometheus-stack-prometheus-rulefiles-0
            name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 2000
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: kube-prometheus-stack-prometheus
        serviceAccountName: kube-prometheus-stack-prometheus
        terminationGracePeriodSeconds: 600
        volumes:
        - name: config
          secret:
            defaultMode: 420
            secretName: prometheus-kube-prometheus-stack-prometheus
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
            - secret:
                name: prometheus-kube-prometheus-stack-prometheus-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - configMap:
            defaultMode: 420
            name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
          name: prometheus-kube-prometheus-stack-prometheus-rulefiles-0
        - name: web-config
          secret:
            defaultMode: 420
            secretName: prometheus-kube-prometheus-stack-prometheus-web-config
        - emptyDir: {}
          name: prometheus-kube-prometheus-stack-prometheus-db
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: prometheus-kube-prometheus-stack-prometheus-57b4489d55
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: prometheus-kube-prometheus-stack-prometheus-57b4489d55
    updatedReplicas: 1
kind: List
metadata:
  resourceVersion: ""
